"""State models for the LangGraph orchestrator.

This module defines the execution state for agentic workflows,
tracking conversation, tool calls, and workflow progress.
"""
from __future__ import annotations

import operator
from pathlib import Path
from typing import TYPE_CHECKING, Annotated, Literal

from pydantic import BaseModel, ConfigDict, Field

from amelia.core.agentic_state import AgenticStatus, ToolCall, ToolResult
from amelia.core.types import Design, Issue


if TYPE_CHECKING:
    from amelia.agents.evaluator import EvaluationResult
    from amelia.agents.reviewer import StructuredReviewResult


Severity = Literal["low", "medium", "high", "critical"]


class ReviewResult(BaseModel):
    """Result from a code review.

    Attributes:
        reviewer_persona: The persona or role of the reviewer.
        approved: Whether the review approved the changes.
        comments: List of actionable issues to fix. Filtered at creation time
            to exclude positive observations.
        severity: Severity level of issues found (low, medium, high, critical).
    """
    model_config = ConfigDict(frozen=True)

    reviewer_persona: str
    approved: bool
    comments: list[str]
    severity: Severity


class ExecutionState(BaseModel):
    """State for the LangGraph orchestrator execution.

    This model is frozen (immutable) to support the stateless reducer pattern.
    Use model_copy(update={...}) to create modified copies.

    Attributes:
        profile_id: ID of the active profile (for replay determinism).
            The actual Profile object is passed via config["configurable"]["profile"].
        issue: The issue being worked on.
        design: Optional design context from brainstorming or external upload.
        goal: High-level goal for agentic execution.
        base_commit: Git commit SHA captured at workflow start for accurate diffing.
        plan_markdown: The markdown plan content generated by the Architect.
        raw_architect_output: Raw markdown output from agentic architect execution.
            Temporary field until #199 validator parses into structured fields.
        plan_path: Path where the markdown plan was saved.
        human_approved: Whether human approval was granted for the goal/strategy.
        human_feedback: Optional feedback from human during approval.
        last_review: Most recent review result (only latest matters for decisions).
        code_changes_for_review: Staged code changes for review.
        driver_session_id: Session ID for driver session continuity.
        workflow_status: Status of the workflow (running, completed, failed).
        agent_history: History of agent actions/messages for context tracking.
            Uses operator.add reducer - new entries are appended across state updates.
        tool_calls: History of tool calls made during agentic execution.
            Uses operator.add reducer - new calls are appended across state updates.
        tool_results: History of tool results from agentic execution.
            Uses operator.add reducer - new results are appended across state updates.
        status: Current agentic execution status.
        final_response: Final response from the agent when complete.
        error: Error message if status is 'failed'.
        review_iteration: Current iteration in review-fix loop.
        total_tasks: Number of tasks parsed from plan (None = legacy single-session mode).
        current_task_index: 0-indexed task being executed, increments after each task passes review.
        task_review_iteration: Review iteration counter that resets to 0 when moving to next task.
        structured_review: Structured review output from reviewer agent.
        evaluation_result: Output from the evaluator agent.
        approved_items: Item numbers approved for fixing by human or auto-approve.
        auto_approve: Whether to skip human approval steps.
        review_pass: Current review iteration in auto mode.
        max_review_passes: Maximum iterations allowed in auto mode.
    """

    model_config = ConfigDict(frozen=True)

    profile_id: str
    issue: Issue | None = None
    design: Design | None = None
    goal: str | None = None
    base_commit: str | None = None  # Git commit SHA at workflow start for diffing
    plan_markdown: str | None = None
    raw_architect_output: str | None = None  # Raw output from agentic architect
    plan_path: Path | None = None
    key_files: list[str] = Field(default_factory=list)
    """List of key files identified in the plan."""
    human_approved: bool | None = None
    human_feedback: str | None = None
    last_review: ReviewResult | None = None
    code_changes_for_review: str | None = None
    driver_session_id: str | None = None
    workflow_status: Literal["running", "completed", "failed", "aborted"] = "running"
    agent_history: Annotated[list[str], operator.add] = Field(default_factory=list)

    # Agentic execution tracking
    tool_calls: Annotated[list[ToolCall], operator.add] = Field(default_factory=list)
    tool_results: Annotated[list[ToolResult], operator.add] = Field(default_factory=list)
    agentic_status: AgenticStatus = "running"
    final_response: str | None = None
    error: str | None = None

    # Review iteration tracking (for review-fix loop)
    review_iteration: int = 0

    # Task execution tracking (for multi-task plans)
    total_tasks: int | None = None  # Parsed from plan (None = legacy single-session)
    current_task_index: int = 0  # 0-indexed, increments after each task passes review
    task_review_iteration: int = 0  # Resets to 0 when moving to next task

    # Review workflow fields (structured review-fix cycle)
    structured_review: StructuredReviewResult | None = None
    evaluation_result: EvaluationResult | None = None
    approved_items: list[int] = Field(default_factory=list)
    auto_approve: bool = False
    review_pass: int = 0
    max_review_passes: int = 3


def rebuild_execution_state() -> None:
    """Rebuild ExecutionState to resolve forward references.

    Must be called after importing StructuredReviewResult and EvaluationResult
    to enable Pydantic validation and Python's get_type_hints() to work.

    This function:
    1. Imports the forward-referenced types
    2. Injects them into this module's global namespace (required for get_type_hints)
    3. Calls model_rebuild() to refresh Pydantic's type resolution

    Example:
        from amelia.core.state import rebuild_execution_state
        rebuild_execution_state()
    """
    import sys  # noqa: PLC0415

    from amelia.agents.evaluator import EvaluationResult  # noqa: PLC0415
    from amelia.agents.reviewer import StructuredReviewResult  # noqa: PLC0415

    # Inject types into this module's namespace for get_type_hints() compatibility.
    # These dynamic assignments are required for Python's typing.get_type_hints()
    # to resolve forward references when used by LangGraph's StateGraph.
    module = sys.modules[__name__]
    module.StructuredReviewResult = StructuredReviewResult  # type: ignore[attr-defined]
    module.EvaluationResult = EvaluationResult  # type: ignore[attr-defined]

    ExecutionState.model_rebuild(
        _types_namespace={
            "StructuredReviewResult": StructuredReviewResult,
            "EvaluationResult": EvaluationResult,
        }
    )

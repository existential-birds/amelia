# Codex and Explicit CLI Drivers — Completion Plan

**Goal:** Complete remaining work from the codex-driver-design plan: implement real codex CLI streaming, add missing test coverage for codex paths, fix remaining legacy `cli` references in docs and tests, update CHANGELOG, and run full verification.

**Architecture:** The CodexCliDriver scaffold is already in place with all DriverInterface methods implemented. The `_run_codex_stream()` method is the only placeholder. Remaining work is: (1) replace the placeholder streaming method with a real subprocess-based NDJSON streaming implementation, (2) add codex to the multi-driver integration test matrix, (3) add missing CLI config tests for codex, (4) fix legacy `cli` references in README.md, test fixtures, and docs, (5) add CHANGELOG breaking changes entry, and (6) run full verification.

**Tech Stack:** Python 3.12, pytest, pytest-asyncio, subprocess, pydantic, typer

---

## Phase 1: Implement Real Codex CLI Streaming

### Task 1: Write failing test for `_run_codex_stream` with real subprocess integration

**Files:**
- Modify: `tests/unit/drivers/test_codex_driver.py`

**Step 1: Write failing tests for `_run_codex_stream` subprocess integration**

Add tests that verify `_run_codex_stream` actually spawns a subprocess and yields parsed NDJSON events. These tests mock the subprocess layer but verify the parsing and event-yielding logic.

```python
import subprocess
from unittest.mock import MagicMock, patch


def test_run_codex_stream_yields_parsed_ndjson_events() -> None:
    """_run_codex_stream should spawn codex subprocess and yield parsed NDJSON lines."""
    driver = CodexCliDriver(model="gpt-5-codex", cwd="/tmp")

    ndjson_output = (
        '{"type": "reasoning", "content": "thinking hard"}\n'
        '{"type": "tool_call", "name": "read_file", "input": {"path": "a.py"}, "id": "t1"}\n'
        '{"type": "tool_result", "name": "read_file", "output": "content", "id": "t1"}\n'
        '{"type": "final", "content": "done"}\n'
    )

    mock_process = MagicMock()
    mock_process.stdout = ndjson_output.encode().split(b"\n")
    mock_process.stdout = [line + b"\n" for line in ndjson_output.encode().split(b"\n") if line]
    mock_process.returncode = 0
    mock_process.wait.return_value = 0

    with patch("subprocess.Popen", return_value=mock_process):
        events = list(driver._run_codex_stream("do something", cwd="/tmp"))

    assert len(events) == 4
    assert events[0] == {"type": "reasoning", "content": "thinking hard"}
    assert events[1]["type"] == "tool_call"
    assert events[1]["name"] == "read_file"
    assert events[3] == {"type": "final", "content": "done"}


def test_run_codex_stream_skips_malformed_json_lines() -> None:
    """_run_codex_stream should skip lines that are not valid JSON."""
    driver = CodexCliDriver(model="gpt-5-codex", cwd="/tmp")

    ndjson_output = (
        'not valid json\n'
        '{"type": "final", "content": "ok"}\n'
    )

    mock_process = MagicMock()
    mock_process.stdout = [line.encode() + b"\n" for line in ndjson_output.strip().split("\n")]
    mock_process.returncode = 0
    mock_process.wait.return_value = 0

    with patch("subprocess.Popen", return_value=mock_process):
        events = list(driver._run_codex_stream("do something", cwd="/tmp"))

    assert len(events) == 1
    assert events[0] == {"type": "final", "content": "ok"}


def test_run_codex_stream_raises_on_nonzero_exit() -> None:
    """_run_codex_stream should raise ModelProviderError on non-zero exit code."""
    driver = CodexCliDriver(model="gpt-5-codex", cwd="/tmp")

    mock_process = MagicMock()
    mock_process.stdout = []
    mock_process.stderr = MagicMock()
    mock_process.stderr.read.return_value = b"codex crashed"
    mock_process.returncode = 1
    mock_process.wait.return_value = 1

    with patch("subprocess.Popen", return_value=mock_process):
        with pytest.raises(ModelProviderError, match="Codex CLI streaming failed"):
            list(driver._run_codex_stream("do something", cwd="/tmp"))
```

**Step 2: Run tests to verify they fail**

Run: `uv run pytest tests/unit/drivers/test_codex_driver.py -v -k "stream"`
Expected: FAIL because `_run_codex_stream` is still a placeholder that yields a single `{"type": "placeholder"}` event.

**Step 3: Implement `_run_codex_stream` with real subprocess NDJSON parsing**

Replace the placeholder in `amelia/drivers/cli/codex.py` lines 86-107:

```python
def _run_codex_stream(self, prompt: str, cwd: str | None = None, **kwargs: Any) -> Iterator[dict[str, Any]]:
    """Run codex CLI command and stream NDJSON events.

    Spawns a synchronous subprocess with ``codex exec --stream --json``
    and yields one parsed dict per newline-delimited JSON line.

    Args:
        prompt: The prompt to send to codex.
        cwd: Working directory override (falls back to self.cwd).
        **kwargs: Additional arguments (currently unused).

    Yields:
        Event dictionaries parsed from codex CLI NDJSON output.

    Raises:
        ModelProviderError: If codex CLI exits with non-zero status.
    """
    cmd = ["codex", "exec", "--stream", "--json"]

    if self.model:
        cmd.extend(["--model", self.model])

    cmd.extend(["--", prompt])

    proc = subprocess.Popen(
        cmd,
        cwd=cwd or self.cwd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )

    try:
        for raw_line in proc.stdout:  # type: ignore[union-attr]
            line = raw_line.decode("utf-8", errors="replace").strip()
            if not line:
                continue
            try:
                event = json.loads(line)
                if isinstance(event, dict):
                    yield event
            except json.JSONDecodeError:
                continue  # skip malformed lines
    finally:
        proc.wait()
        if proc.returncode and proc.returncode != 0:
            stderr_text = ""
            if proc.stderr:
                stderr_text = proc.stderr.read().decode("utf-8", errors="replace").strip()[:1000]
            raise ModelProviderError(
                f"Codex CLI streaming failed with exit code {proc.returncode}: {stderr_text}",
                provider_name=self.PROVIDER_NAME,
                original_message=stderr_text,
            )
```

Also add `import subprocess` at the top of the file (after `import asyncio`).

**Step 4: Run tests to verify they pass**

Run: `uv run pytest tests/unit/drivers/test_codex_driver.py -v`
Expected: ALL PASS

**Step 5: Commit**

```bash
git add amelia/drivers/cli/codex.py tests/unit/drivers/test_codex_driver.py
git commit -m "feat(drivers): implement codex cli streaming via subprocess NDJSON"
```

---

## Phase 2: Add Codex to Integration Test Matrix

### Task 2: Add codex driver to multi-driver integration parametrization

**Files:**
- Modify: `tests/integration/test_multi_driver_agents.py:34-45`
- Modify: `tests/integration/test_multi_driver_agents.py:86-89,143-146,192-195,234-237`

**Step 1: Add codex entry to `DRIVER_CONFIGS` and fix patch routing**

In `tests/integration/test_multi_driver_agents.py`, update the `DRIVER_CONFIGS` list at line 34 and the patch routing logic in each test method:

```python
# Replace DRIVER_CONFIGS (line 34-45)
DRIVER_CONFIGS = [
    pytest.param(
        "api",
        "openrouter:anthropic/claude-sonnet-4",
        id="api-openrouter",
    ),
    pytest.param(
        "claude",
        "sonnet",
        id="cli-claude",
    ),
    pytest.param(
        "codex",
        "gpt-5-codex",
        id="cli-codex",
    ),
]
```

Update all four patch routing blocks (lines 86-89, 143-146, 192-195, 234-237) from:

```python
if driver_key.startswith("api:"):
    patch_target = "amelia.drivers.api.deepagents.ApiDriver.execute_agentic"
else:
    patch_target = "amelia.drivers.cli.claude.ClaudeCliDriver.execute_agentic"
```

to:

```python
if driver_key == "api":
    patch_target = "amelia.drivers.api.deepagents.ApiDriver.execute_agentic"
elif driver_key == "codex":
    patch_target = "amelia.drivers.cli.codex.CodexCliDriver.execute_agentic"
else:
    patch_target = "amelia.drivers.cli.claude.ClaudeCliDriver.execute_agentic"
```

**Step 2: Run the integration tests to verify**

Run: `uv run pytest tests/integration/test_multi_driver_agents.py -v`
Expected: All tests pass for all 3 driver parametrizations (api-openrouter, cli-claude, cli-codex).

**Step 3: Commit**

```bash
git add tests/integration/test_multi_driver_agents.py
git commit -m "test(integration): add codex driver to multi-driver test matrix"
```

---

## Phase 3: Add Missing CLI Config Tests for Codex

### Task 3: Add codex driver acceptance and legacy rejection tests to CLI config

**Files:**
- Modify: `tests/unit/cli/test_config_cli.py`

**Step 1: Write the failing tests**

Add two tests to `TestProfileCreate` class in `tests/unit/cli/test_config_cli.py`:

```python
def test_profile_create_accepts_codex_driver(
    self, runner: CliRunner, mock_db: MagicMock
) -> None:
    """'amelia config profile create' accepts codex driver."""
    created_profile = Profile(
        name="codex-profile",
        tracker="noop",
        working_dir="/tmp",
        agents={
            "architect": AgentConfig(driver="codex", model="gpt-5-codex"),
            "developer": AgentConfig(driver="codex", model="gpt-5-codex"),
            "reviewer": AgentConfig(driver="codex", model="gpt-5-codex"),
            "plan_validator": AgentConfig(driver="codex", model="gpt-5-codex"),
        },
    )

    mock_repo = MagicMock()
    mock_repo.get_profile = AsyncMock(return_value=None)
    mock_repo.create_profile = AsyncMock(return_value=created_profile)

    with patch("amelia.cli.config.get_database", return_value=mock_db), \
         patch("amelia.cli.config.ProfileRepository", return_value=mock_repo):
        result = runner.invoke(app, [
            "config", "profile", "create", "codex-profile",
            "--driver", "codex",
            "--model", "gpt-5-codex",
            "--tracker", "noop",
            "--working-dir", "/tmp",
        ])

    assert result.exit_code == 0
    assert "created successfully" in result.stdout
    mock_repo.create_profile.assert_called_once()

def test_profile_create_rejects_legacy_cli_driver(
    self, runner: CliRunner, mock_db: MagicMock
) -> None:
    """'amelia config profile create' rejects legacy 'cli' driver."""
    mock_repo = MagicMock()
    mock_repo.get_profile = AsyncMock(return_value=None)

    with patch("amelia.cli.config.get_database", return_value=mock_db), \
         patch("amelia.cli.config.ProfileRepository", return_value=mock_repo):
        result = runner.invoke(app, [
            "config", "profile", "create", "bad-profile",
            "--driver", "cli",
            "--model", "sonnet",
            "--tracker", "noop",
            "--working-dir", "/tmp",
        ])

    assert result.exit_code != 0
    assert "Invalid driver" in result.stdout
```

**Step 2: Run tests to verify they pass (these should pass immediately since config already supports codex)**

Run: `uv run pytest tests/unit/cli/test_config_cli.py -k "codex or legacy_cli" -v`
Expected: PASS (config.py already validates correctly)

**Step 3: Commit**

```bash
git add tests/unit/cli/test_config_cli.py
git commit -m "test(cli): add codex acceptance and legacy cli rejection config tests"
```

---

## Phase 4: Fix Legacy `cli` References in Docs and Tests

### Task 4: Fix README.md legacy `cli` driver reference

**Files:**
- Modify: `README.md:24`

**Step 1: Update the legacy reference**

Change line 24 of `README.md` from:

```markdown
  - Claude CLI installed (for `cli` driver)
```

to:

```markdown
  - Claude CLI installed (for `claude` driver) or Codex CLI installed (for `codex` driver)
```

**Step 2: Verify no legacy references remain in README**

Run: `rg -n "for .cli. driver|--driver cli|driver: cli" README.md`
Expected: No matches.

**Step 3: Commit**

```bash
git add README.md
git commit -m "docs(readme): update legacy cli driver reference to claude and codex"
```

### Task 5: Fix legacy `cli` references in integration test fixtures

**Files:**
- Modify: `tests/integration/test_cli_task_option.py:33,52`

**Step 1: Update the legacy YAML fixture values**

In `tests/integration/test_cli_task_option.py`, change the two YAML fixture strings from `driver: cli` to `driver: claude`:

Line 33:
```python
    driver: claude
```

Line 52:
```python
    driver: claude
```

**Step 2: Run tests to verify**

Run: `uv run pytest tests/integration/test_cli_task_option.py -v`
Expected: PASS

**Step 3: Commit**

```bash
git add tests/integration/test_cli_task_option.py
git commit -m "test: migrate cli to claude in CLI task option integration fixtures"
```

### Task 6: Fix legacy `cli` reference in mem0-reviewer-integration plan doc

**Files:**
- Modify: `docs/plans/mem0-reviewer-integration.md:1205`

**Step 1: Update the legacy reference**

Change line 1205 from:

```bash
amelia config profile create work --driver cli --model sonnet --tracker github --activate
```

to:

```bash
amelia config profile create work --driver claude --model sonnet --tracker github --activate
```

**Step 2: Commit**

```bash
git add docs/plans/mem0-reviewer-integration.md
git commit -m "docs: fix legacy cli driver reference in mem0-reviewer plan"
```

---

## Phase 5: CHANGELOG Breaking Changes Entry

### Task 7: Add breaking changes entry to CHANGELOG.md

**Files:**
- Modify: `CHANGELOG.md:8-9`

**Step 1: Add the breaking changes entry under `[Unreleased]`**

Insert after line 8 (`## [Unreleased]`):

```markdown
### Changed

- **Breaking:** Replace legacy `cli` driver with explicit `claude` and `codex` drivers ([#473](https://github.com/existential-birds/amelia/issues/473))

  The generic `driver: "cli"` value has been split into explicit driver keys:
  - `claude` — wraps the Claude CLI binary
  - `codex` — wraps the OpenAI Codex CLI binary
  - `api` — unchanged (direct OpenRouter API calls)

  **Migration:** Update all profiles that use `driver: "cli"` to `driver: "claude"`. Legacy `cli` values are now rejected at startup. Recreate profiles with `amelia config profile create <name> --driver claude`.

### Added

- **drivers:** Add `CodexCliDriver` for OpenAI Codex CLI integration with subprocess-based NDJSON streaming
```

**Step 2: Verify the entry is well-formed**

Run: `head -25 CHANGELOG.md`
Expected: Shows the new entry under `[Unreleased]`.

**Step 3: Commit**

```bash
git add CHANGELOG.md
git commit -m "docs(changelog): add breaking change entry for explicit driver keys"
```

---

## Phase 6: Full Verification Gate

### Task 8: Run targeted driver and unit tests

**Files:**
- None (verification only)

**Step 1: Run all driver-related unit tests**

Run: `uv run pytest tests/unit/drivers/test_codex_driver.py tests/unit/drivers/test_factory.py tests/unit/test_driver_factory.py tests/unit/core/test_types.py -v`
Expected: ALL PASS

**Step 2: Run CLI config and orchestration tests**

Run: `uv run pytest tests/unit/cli/test_config_cli.py tests/unit/test_orchestrator_profile.py tests/unit/test_orchestrator_graph.py -v`
Expected: ALL PASS

**Step 3: Run integration tests**

Run: `uv run pytest tests/integration/test_multi_driver_agents.py tests/integration/test_extraction_driver_instantiation.py -v`
Expected: ALL PASS

**Step 4: Run static analysis**

Run: `uv run ruff check .`
Expected: No errors

Run: `uv run mypy amelia/drivers/cli/codex.py amelia/drivers/factory.py amelia/core/types.py`
Expected: No errors

### Task 9: Verify no legacy `cli` driver references remain

**Step 1: Search for legacy references in source code and docs**

Run: `rg -n '"cli"|DriverType\.CLI|--driver cli|driver: cli|for .cli. driver' amelia tests README.md docs/site`
Expected: Only matches in:
- `tests/unit/test_driver_factory.py:32` — intentional test that `get_driver("cli")` is rejected
- `tests/unit/drivers/test_factory.py:33` — intentional test that `get_driver("cli")` is rejected
- `tests/unit/core/test_types.py:34-36` — intentional test that `AgentConfig(driver="cli")` is rejected
- `docs/plans/2026-02-18-codex-driver-design.md` — the original design doc (historical, ok to keep)

Any other matches indicate incomplete migration and must be fixed before merging.

**Step 2: Run full test suite**

Run: `uv run pytest tests/unit tests/integration -v --timeout=60`
Expected: ALL PASS

**Step 3: Review commit log**

Run: `git log --oneline -n 10`
Expected: Clean linear sequence of task commits.

---

## Summary

This plan completes the remaining work from the Codex and Explicit CLI Drivers design:

1. **Phase 1** replaces the placeholder `_run_codex_stream()` with a real subprocess-based NDJSON streaming implementation and adds thorough unit tests.
2. **Phase 2** adds the codex driver to the multi-driver integration test matrix so all three drivers (api, claude, codex) are exercised end-to-end.
3. **Phase 3** adds explicit CLI config tests for codex driver acceptance and legacy `cli` rejection.
4. **Phase 4** fixes all remaining legacy `cli` references in README.md, integration test fixtures, and planning docs.
5. **Phase 5** adds the required CHANGELOG breaking changes entry documenting the migration from `cli` to `claude`/`codex`.
6. **Phase 6** runs the full verification gate: unit tests, integration tests, static analysis, and legacy reference audit.

After all phases pass, the feature is complete and ready for PR.
